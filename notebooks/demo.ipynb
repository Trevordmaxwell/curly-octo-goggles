{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unified Mamba-Hopfield-DEQ Demo\n",
    "\n",
    "This notebook demonstrates the key capabilities of the unified architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.models.unified import UnifiedMambaHopfieldDEQ\n",
    "from experiments.theory.convergence_proofs import ConvergenceValidator\n",
    "from experiments.theory.energy_analysis import EnergyLandscapeAnalyzer\n",
    "\n",
    "# Initialize model\n",
    "model = UnifiedMambaHopfieldDEQ(\n",
    "    vocab_size=1000,\n",
    "    d_model=128,\n",
    "    d_state=32,\n",
    "    memory_size=500,\n",
    "    max_iterations=20\n",
    ")\n",
    "\n",
    "print(\"Model initialized!\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "Let's run a simple forward pass and examine the equilibrium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy input\n",
    "input_ids = torch.randint(0, 1000, (1, 20))\n",
    "\n",
    "# Forward with diagnostics\n",
    "logits, diag = model(input_ids, return_diagnostics=True)\n",
    "\n",
    "print(\"Forward pass complete!\")\n",
    "print(f\"Converged: {diag['solver_info']['converged']}\")\n",
    "print(f\"Iterations: {diag['solver_info']['iterations']}\")\n",
    "print(f\"Final energy: {diag['solver_info']['final_energy']:.4f}\")\n",
    "\n",
    "# Visualize convergence\n",
    "if 'energy_history' in diag['solver_info']:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(diag['solver_info']['energy_history'], 'o-')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Energy')\n",
    "    plt.title('Energy During Convergence')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Dynamics\n",
    "\n",
    "Examine how memory patterns are stored and retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current memory usage\n",
    "memory_stats = diag['memory_usage']\n",
    "print(f\"Memory attention entropy: {memory_stats['attention_entropy']:.4f}\")\n",
    "print(f\"Top-10 pattern mass: {memory_stats['top_10_mass']:.4f}\")\n",
    "\n",
    "# Visualize attention over memory\n",
    "z_eq = diag['z_equilibrium']\n",
    "with torch.no_grad():\n",
    "    similarities = torch.matmul(z_eq, model.memory_patterns.T)\n",
    "    attention = torch.softmax(similarities, dim=-1)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(len(attention[0])), attention[0].cpu().numpy())\n",
    "plt.xlabel('Memory Pattern Index')\n",
    "plt.ylabel('Attention Weight')\n",
    "plt.title('Memory Retrieval Pattern')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "top_k = 20\n",
    "top_indices = attention[0].topk(top_k).indices.cpu().numpy()\n",
    "top_values = attention[0].topk(top_k).values.cpu().numpy()\n",
    "plt.barh(range(top_k), top_values)\n",
    "plt.xlabel('Attention Weight')\n",
    "plt.ylabel('Pattern Rank')\n",
    "plt.title(f'Top {top_k} Retrieved Patterns')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical Validation\n",
    "\n",
    "Test convergence properties empirically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = ConvergenceValidator(model)\n",
    "\n",
    "print('Running convergence tests...')\n",
    "print('\n1. Testing contraction property...')\n",
    "contraction_results = validator.test_contraction_property(num_samples=20)\n",
    "\n",
    "print('\n2. Testing energy descent...')\n",
    "descent_results = validator.test_energy_descent(num_trajectories=10, num_steps=20)\n",
    "\n",
    "print('\n3. Testing fixed-point stability...')\n",
    "stability_results = validator.test_fixed_point_stability(num_fixed_points=5)\n",
    "\n",
    "print('\n' + '='*50)\n",
    "print('RESULTS SUMMARY')\n",
    "print('='*50)\n",
    "print(f\"✓ Contraction: {contraction_results['is_contraction']}\")\n",
    "print(f\"✓ Energy Descent: {descent_results['monotonic_descent']}\")\n",
    "print(f\"✓ Stability: {stability_results['is_stable']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy Landscape Visualization\n",
    "\n",
    "Visualize the energy surface around an equilibrium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = EnergyLandscapeAnalyzer(model)\n",
    "\n",
    "# Get an equilibrium point\n",
    "with torch.no_grad():\n",
    "    z_init = torch.randn(1, model.d_model)\n",
    "    context = torch.randn(1, 10, model.d_model)\n",
    "    z_eq, _ = model.solver.solve(z_init, context, model.memory_patterns)\n",
    "\n",
    "# Visualize 2D slice\n",
    "print('Computing energy landscape (this may take a minute)...')\n",
    "energies, residuals = analyzer.visualize_2d_slice(\n",
    "    z_eq, context, resolution=30, radius=2.0\n",
    ")\n",
    "\n",
    "print('Landscape visualization saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associative Memory Capabilities\n",
    "\n",
    "Test key-value retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_associative_recall(model, num_pairs=10):\n",
    "    \"\"\"Simple associative recall test.\"\"\"\n",
    "    keys = torch.randint(0, 500, (num_pairs,))\n",
    "    values = torch.randint(500, 1000, (num_pairs,))\n",
    "\n",
    "    sequence = []\n",
    "    for key, value in zip(keys, values):\n",
    "        sequence.extend([key.item(), value.item()])\n",
    "\n",
    "    query_idx = torch.randint(0, num_pairs, (1,)).item()\n",
    "    query_key = keys[query_idx].item()\n",
    "    target_value = values[query_idx].item()\n",
    "\n",
    "    sequence.append(query_key)\n",
    "    input_ids = torch.tensor(sequence).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids)\n",
    "        prediction = logits[0, -1].argmax().item()\n",
    "\n",
    "    correct = (prediction == target_value)\n",
    "    return correct, prediction, target_value\n",
    "\n",
    "print('Testing associative recall...')\n",
    "num_trials = 20\n",
    "correct_count = 0\n",
    "\n",
    "for trial in range(num_trials):\n",
    "    correct, pred, target = test_associative_recall(model, num_pairs=10)\n",
    "    correct_count += correct\n",
    "    if trial < 5:\n",
    "        print(f\"Trial {trial+1}: Pred={pred}, Target={target}, {'✓' if correct else '✗'}\")\n",
    "\n",
    "accuracy = correct_count / num_trials\n",
    "print(f\"\nAccuracy: {accuracy:.1%} ({correct_count}/{num_trials})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Exploration\n",
    "\n",
    "Modify parameters and observe effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, FloatSlider, IntSlider\n",
    "\n",
    "@interact(\n",
    "    beta=FloatSlider(min=0.1, max=5.0, step=0.1, value=2.0),\n",
    "    max_iter=IntSlider(min=5, max=50, step=5, value=20),\n",
    "    tolerance=FloatSlider(min=1e-4, max=1e-2, step=1e-4, value=1e-3)\n",
    ")\n",
    "def explore_parameters(beta, max_iter, tolerance):\n",
    "    \"\"\"Interactive parameter exploration.\"\"\"\n",
    "    model.energy_fn.beta = beta\n",
    "    model.dynamics.beta = beta\n",
    "    model.solver.max_iter = max_iter\n",
    "    model.solver.tol_fp = tolerance\n",
    "    model.solver.tol_energy = tolerance\n",
    "\n",
    "    input_ids = torch.randint(0, 1000, (1, 20))\n",
    "    with torch.no_grad():\n",
    "        logits, diag = model(input_ids, return_diagnostics=True)\n",
    "\n",
    "    info = diag['solver_info']\n",
    "    print(f\"Converged: {info['converged']}\")\n",
    "    print(f\"Iterations: {info['iterations']}\")\n",
    "    print(f\"Final energy: {info['final_energy']:.4f}\")\n",
    "\n",
    "    if 'energy_history' in info:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(info['energy_history'], 'o-')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Energy')\n",
    "        plt.title(f'Convergence (β={beta}, max_iter={max_iter}, tol={tolerance})')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
